{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1Z0YqpNWmO-"
   },
   "source": [
    "# ML HW5 sample code\n",
    "TODO:\n",
    " - Complete value iteration algorithm\n",
    " - Implement\n",
    "    1. Greedy action selection\n",
    "    2. Epsilon-greedy or UCB action selection\n",
    "\n",
    "Report:\n",
    " - Make **2** modifications to encourage the agent to play faster\n",
    " - Analyze the public score with and without each modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "p0agtAiAWmPB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import PillowWriter, FuncAnimation\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define constants\n",
    "BOARD_SIZE = 8\n",
    "MAX_ROUNDS = 50\n",
    "OBSTACLES = {(3, 3), (3, 4), (4, 3), (4, 4), (2,2), (2,5), (5,2), (5,5)}\n",
    "PAWN_MOVE_PROB = 0.2\n",
    "\n",
    "# Define hyperparameters\n",
    "REWARD_CATCH = 1.0\n",
    "REWARD_STEP = -0.01\n",
    "GAMMA = 0.95\n",
    "TAU = 0.05\n",
    "num_episodes = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZbrYdQTxWmPC"
   },
   "outputs": [],
   "source": [
    "class ChessEnvironment:\n",
    "    def __init__(self, max_rounds=MAX_ROUNDS):\n",
    "        self.max_rounds = max_rounds\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.knight_pos = self._random_position()\n",
    "        self.pawn_pos = self._random_position()\n",
    "        self.rounds = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.knight_pos, self.pawn_pos = state[:2], state[2:]\n",
    "        self.rounds = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def _random_position(self):\n",
    "        while True:\n",
    "            pos = (random.randint(0, BOARD_SIZE - 1), random.randint(0, BOARD_SIZE - 1))\n",
    "            if pos not in OBSTACLES:\n",
    "                return pos\n",
    "\n",
    "    def _get_state(self):\n",
    "        return (*self.knight_pos, *self.pawn_pos)\n",
    "\n",
    "    def _knight_moves(self, pos):\n",
    "        x, y = pos\n",
    "        moves = [\n",
    "            (x + 2, y + 1), (x + 2, y - 1), (x - 2, y + 1), (x - 2, y - 1),\n",
    "            (x + 1, y + 2), (x + 1, y - 2), (x - 1, y + 2), (x - 1, y - 2)\n",
    "        ]\n",
    "        return [\n",
    "            (nx, ny) for nx, ny in moves\n",
    "            if 0 <= nx < BOARD_SIZE and 0 <= ny < BOARD_SIZE and (nx, ny) not in OBSTACLES\n",
    "        ]\n",
    "\n",
    "    def step(self, knight_action):\n",
    "        self.knight_pos = knight_action\n",
    "        if self.knight_pos == self.pawn_pos:\n",
    "            return self._get_state(), REWARD_CATCH, True\n",
    "\n",
    "        # Adjusted: Pawn only moves downward\n",
    "        if random.random() < PAWN_MOVE_PROB:\n",
    "            px, py = self.pawn_pos\n",
    "            if px < BOARD_SIZE - 1 and (px + 1, py) not in OBSTACLES:\n",
    "                self.pawn_pos = (px + 1, py)\n",
    "\n",
    "        self.rounds += 1\n",
    "        done = self.rounds >= self.max_rounds\n",
    "        return self._get_state(), REWARD_STEP, done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_action_selection(env, state, value_table):\n",
    "    actions = env._knight_moves(state[:2])\n",
    "    if not actions:\n",
    "        return state[:2]\n",
    "    action_values = [\n",
    "        value_table[action[0], action[1], state[2], state[3]] for action in actions\n",
    "    ]\n",
    "    return actions[np.argmax(action_values)]\n",
    "\n",
    "\n",
    "def epsilon_greedy_action_selection(env, state, value_table, epsilon):\n",
    "    actions = env._knight_moves(state[:2])\n",
    "    if not actions:\n",
    "        return state[:2]\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice(actions)\n",
    "    else:\n",
    "        return greedy_action_selection(env, state, value_table)\n",
    "\n",
    "\n",
    "def ucb_action_selection(env, state, value_table, count_table, c=2):\n",
    "    actions = env._knight_moves(state[:2])\n",
    "    if not actions:\n",
    "        return state[:2]\n",
    "    total_visits = sum(\n",
    "        count_table[action[0], action[1], state[2], state[3]] for action in actions\n",
    "    )\n",
    "    ucb_values = [\n",
    "        value_table[action[0], action[1], state[2], state[3]] +\n",
    "        c * np.sqrt(np.log(total_visits + 1) /\n",
    "                    (count_table[action[0], action[1], state[2], state[3]] + 1e-5))\n",
    "        for action in actions\n",
    "    ]\n",
    "    return actions[np.argmax(ucb_values)]    \n",
    "    \n",
    "\n",
    "def train_agent():\n",
    "    env = ChessEnvironment()\n",
    "    value_table = np.zeros((BOARD_SIZE, BOARD_SIZE, BOARD_SIZE, BOARD_SIZE))\n",
    "    count_table = np.zeros_like(value_table, dtype=int)\n",
    "\n",
    "    for episode in tqdm(range(num_episodes)):\n",
    "        tau = max(0.05, 0.1 - episode / (num_episodes / 2))  \n",
    "        epsilon = max(0.01, 0.5 - (episode / (num_episodes * 0.8)))\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if episode % 10 == 0:\n",
    "                action = ucb_action_selection(env, state, value_table, count_table)\n",
    "            else:\n",
    "                epsilon = max(0.1, 1 - episode / num_episodes)\n",
    "                action = epsilon_greedy_action_selection(env, state, value_table, epsilon)\n",
    "\n",
    "            next_state, reward, done = env.step(action)\n",
    "\n",
    "            next_actions = env._knight_moves(next_state[:2])\n",
    "            max_next_value = max(\n",
    "                [value_table[action[0], action[1], next_state[2], next_state[3]] for action in next_actions],\n",
    "                default=0\n",
    "            )\n",
    "\n",
    "            current_value = value_table[state[0], state[1], state[2], state[3]]\n",
    "            value_table[state[0], state[1], state[2], state[3]] = current_value + tau * (\n",
    "                reward + GAMMA * max_next_value - current_value\n",
    "            )\n",
    "\n",
    "            count_table[state[0], state[1], state[2], state[3]] += 1\n",
    "            state = next_state\n",
    "\n",
    "    return value_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VGg4I7IFWmPD"
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def finish_game(value_table, env):\n",
    "    # Generate frames of a complete game with progress bar.\n",
    "    state = env._get_state()\n",
    "    frames = []\n",
    "    done = False\n",
    "    step = 0\n",
    "    while not done:\n",
    "        frames.append((*state, step))\n",
    "        action = greedy_action_selection(env, state, value_table)\n",
    "        next_state, _, done = env.step(action)\n",
    "        state = next_state\n",
    "        step += 1\n",
    "    frames.append((*state, step))\n",
    "    return frames\n",
    "\n",
    "def render_frame(kx, ky, px, py, step, max_steps):\n",
    "    fig, ax = plt.subplots(figsize=(6, 7))  # Add extra space for the progress bar\n",
    "\n",
    "    # Plot the chessboard\n",
    "    ax.set_xlim(0, BOARD_SIZE-1)\n",
    "    ax.set_ylim(0, BOARD_SIZE-1)\n",
    "    ax.set_xticks(range(BOARD_SIZE))\n",
    "    ax.set_yticks(range(BOARD_SIZE))\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Draw the obstacles at the center of grid cells\n",
    "    for x, y in OBSTACLES:\n",
    "        ax.text(y, BOARD_SIZE - 1 - x, \"O\", ha=\"center\", va=\"center\", fontsize=20, color=\"black\")\n",
    "\n",
    "    # Draw the knight at the center of its grid cell\n",
    "    ax.text(ky, BOARD_SIZE - 1 - kx, \"K\", ha=\"center\", va=\"center\", fontsize=20, color=\"blue\")\n",
    "\n",
    "    # Draw the pawn at the center of its grid cell\n",
    "    ax.text(py, BOARD_SIZE - 1 - px, \"P\", ha=\"center\", va=\"center\", fontsize=20, color=\"red\")\n",
    "\n",
    "    # Add a title\n",
    "    ax.set_title(\"Catch the Pawn\")\n",
    "\n",
    "    # Add a progress bar below the chessboard\n",
    "    bar_ax = fig.add_axes([0.1, 0.05, 0.8, 0.05])  # [left, bottom, width, height]\n",
    "    bar_ax.barh(0, width=step / (max_steps-1), height=1, color=\"green\")\n",
    "    bar_ax.set_xlim(0, 1)\n",
    "    bar_ax.axis(\"off\")\n",
    "    bar_ax.text(0.5, 0, f\"Step: {step}/{max_steps-1}\", ha=\"center\", va=\"center\", fontsize=12, color=\"white\")\n",
    "\n",
    "    # Convert the figure to a PIL image\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.canvas.get_width_height()\n",
    "    img = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8').reshape(height, width, 3)\n",
    "    pil_img = Image.fromarray(img)\n",
    "\n",
    "    plt.close(fig)\n",
    "    return pil_img\n",
    "\n",
    "def fig_to_array(fig):\n",
    "    fig.canvas.draw()\n",
    "    width, height = fig.canvas.get_width_height()\n",
    "    return np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8').reshape(height, width, 3)\n",
    "\n",
    "def save_gif(frames, filename=\"game.gif\"):\n",
    "    frames[0].save(\n",
    "        filename, save_all=True, append_images=frames[1:]+frames[-1:]*3, duration=500, loop=0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EmFxrSzwWmPD",
    "outputId": "fc9a3981-9789-4d80-d3f9-e221a8a5e85a"
   },
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "# value_table = train_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rI3vDRahWmPE"
   },
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "7wr6XA4eWmPE",
    "outputId": "281a40c4-10c9-4d41-8f64-a66cadd7ebc9"
   },
   "outputs": [],
   "source": [
    "# import IPython\n",
    "# # Create game frames and save as gif\n",
    "# env = ChessEnvironment()\n",
    "# frames = finish_game(value_table, env)\n",
    "\n",
    "# # save_gif(frames)\n",
    "# save_gif([render_frame(*f, len(frames)) for f in frames])\n",
    "# IPython.display.Image(filename=\"game.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAxtowOuWmPF"
   },
   "source": [
    "# Testing\n",
    "**Submit your value_table.npy to Cool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "nkbb0KlSWmPF"
   },
   "outputs": [],
   "source": [
    "# Save the value table\n",
    "# np.save(\"value_table.npy\", value_table)\n",
    "\n",
    "# # Load the value table\n",
    "import os\n",
    "#value_table = np.load(os.path.join(\"96.1\", \"value_table_test_0.npy\"))\n",
    "\n",
    "value_table = np.load('C:\\\\Users\\\\cdpss\\\\Downloads\\\\988\\\\value_table.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mi2pzATLWmPF"
   },
   "source": [
    "### Evaluate on the Public cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3bv6BCEnWmPF"
   },
   "outputs": [],
   "source": [
    "# 100 public states\n",
    "public_states = [(1, 7, 7, 5), (6, 7, 7, 2), (6, 2, 6, 2), (1, 1, 1, 5), (2, 1, 1, 1), (4, 2, 1, 6), (5, 7, 5, 3), (5, 4, 1, 0), (6, 5, 2, 3), (2, 4, 1, 0), (3, 6, 5, 7), (0, 3, 1, 3), (0, 7, 5, 3), (3, 5, 1, 5), (2, 1, 7, 5), (1, 5, 1, 6), (1, 2, 6, 6), (7, 5, 4, 2), (6, 7, 7, 4), (2, 6, 7, 6), (7, 3, 7, 5), (0, 6, 7, 6), (6, 5, 1, 4), (2, 6, 2, 1), (3, 2, 6, 4), (0, 3, 2, 4), (7, 2, 5, 1), (3, 6, 1, 0), (6, 4, 0, 3), (6, 1, 5, 3), (5, 4, 4, 1), (7, 7, 1, 6), (4, 7, 5, 4), (5, 6, 0, 4), (2, 6, 0, 3), (7, 0, 1, 4), (6, 4, 1, 4), (0, 2, 3, 0), (4, 6, 1, 0), (1, 1, 7, 4), (1, 4, 6, 2), (1, 2, 4, 1), (4, 7, 0, 1), (5, 4, 2, 6), (6, 4, 6, 0), (2, 1, 1, 5), (5, 3, 2, 6), (6, 7, 2, 0), (6, 3, 0, 6), (6, 1, 3, 7), (5, 7, 1, 3), (0, 6, 1, 6), (0, 6, 6, 2), (4, 1, 1, 5), (7, 1, 3, 2), (7, 6, 1, 3), (1, 7, 1, 4), (5, 6, 1, 1), (5, 1, 6, 2), (0, 4, 2, 1), (0, 2, 1, 4), (6, 1, 7, 4), (7, 3, 3, 5), (3, 5, 6, 7), (0, 4, 6, 1), (2, 1, 7, 2), (0, 1, 5, 3), (4, 7, 3, 1), (7, 7, 4, 0), (4, 7, 2, 3), (1, 4, 1, 1), (1, 2, 1, 0), (6, 4, 0, 0), (7, 3, 1, 1), (2, 4, 1, 7), (2, 0, 4, 5), (7, 1, 5, 4), (1, 5, 1, 5), (1, 7, 2, 1), (7, 4, 3, 7), (6, 4, 2, 0), (4, 2, 6, 1), (3, 0, 0, 6), (4, 2, 0, 6), (2, 6, 6, 7), (2, 6, 7, 5), (2, 3, 3, 2), (7, 1, 3, 6), (2, 1, 6, 5), (2, 7, 7, 5), (7, 4, 7, 4), (4, 6, 6, 5), (2, 1, 2, 1), (2, 1, 5, 0), (1, 0, 0, 1), (5, 0, 3, 5), (0, 0, 3, 5), (6, 3, 0, 3), (4, 5, 6, 4), (1, 7, 3, 1)]\n",
    "\n",
    "# Eval environment (score = 100 - rounds)\n",
    "class EvalEnvironment:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.knight_pos = self._random_position()\n",
    "        self.pawn_pos = self._random_position()\n",
    "        self.rounds = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def set_state(self, state):\n",
    "        \"\"\"Set the state of the game.\"\"\"\n",
    "        self.knight_pos, self.pawn_pos = state[:2], state[2:]\n",
    "        self.rounds = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def _random_position(self):\n",
    "        while True:\n",
    "            pos = (random.randint(0, BOARD_SIZE - 1), random.randint(0, BOARD_SIZE - 1))\n",
    "            if pos not in OBSTACLES:\n",
    "                return pos\n",
    "\n",
    "    def _get_state(self):\n",
    "        return (*self.knight_pos, *self.pawn_pos)\n",
    "\n",
    "    def _knight_moves(self, pos):\n",
    "        x, y = pos\n",
    "        moves = [\n",
    "            (x + 2, y + 1), (x + 2, y - 1), (x - 2, y + 1), (x - 2, y - 1),\n",
    "            (x + 1, y + 2), (x + 1, y - 2), (x - 1, y + 2), (x - 1, y - 2)\n",
    "        ]\n",
    "        return [\n",
    "            (nx, ny) for nx, ny in moves\n",
    "            if 0 <= nx < BOARD_SIZE and 0 <= ny < BOARD_SIZE and (nx, ny) not in OBSTACLES\n",
    "        ]\n",
    "\n",
    "    def step(self, knight_action):\n",
    "        # Update knight position\n",
    "        self.knight_pos = knight_action\n",
    "\n",
    "        # Check for termination\n",
    "        if self.knight_pos == self.pawn_pos:\n",
    "            return self._get_state(), 100-self.rounds, True\n",
    "\n",
    "        # Pawn's random movement\n",
    "        if random.random() < PAWN_MOVE_PROB:\n",
    "            px, py = self.pawn_pos\n",
    "            if px < BOARD_SIZE - 1 and (px + 1, py) not in OBSTACLES:\n",
    "                self.pawn_pos = (px + 1, py)\n",
    "\n",
    "        self.rounds += 1\n",
    "        done = self.rounds >= MAX_ROUNDS\n",
    "        return (self._get_state()), 0, done\n",
    "\n",
    "def finish_game_eval(value_table, env):\n",
    "    # Finish the game and get the score\n",
    "    state = env._get_state()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = greedy_action_selection(env, state, value_table)\n",
    "        state, score, done = env.step(action)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JdDQ_1fhWmPF",
    "outputId": "5f67e431-43e1-4b23-feb6-2e76d026c438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public score: 95.37\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the value table\n",
    "env = EvalEnvironment()\n",
    "\n",
    "# fix the random seed (TA will use this seed)\n",
    "random.seed(42)\n",
    "\n",
    "# run the public cases\n",
    "scores = []\n",
    "for state in public_states:\n",
    "    env.set_state(state)\n",
    "    score = finish_game_eval(value_table, env)\n",
    "    scores.append(score)\n",
    "print(f\"Public score: {sum(scores)/len(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
